# Git Practice
### Jonathan Zhou

[AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit](https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart)

From this article, I learned abou the ungoing lawsuit against the use of millions of individual artists' artwork to train AIs without their consent; that aside from just art AIs that have been popular on social media, there are other lawsuits going on for the use of data without consent of owners, such as Github Autopilot, which uses code from repositories to train. 

The lawers have describe the suit as “another step toward mak­ing AI fair & eth­i­cal for every­one.” I think this lawsuit brings to light just how troublesome it is for society to deal with data, and how problematic our rapid advancements in data collection and machine learning has become. I also found it interesting that the AIs do not actually store images, "but rather mathematical representations of patterns collected from these images." This makes copyright laws and fair use rules even more difficult to reinforce, as one may argue that the artworks themselves are not being copied, and therefore the use of these public artworks do not exactly violate copyright rules, as least not in a way we're familar with. 

Moving forward with similar technologies such as ChatGPT on the rise, I wonder what the future of AI will look like, and whether its existence will change the norms of our society as we currently know it; it's both exciting and terrifying.

### Comment from Rohan Khanderia (rk3904)
I found the article linked about the ongoing lawsuit really intersting! I've always been under the assumption that they don't actually store people's art, but rather train the model of millions of different art piece so it knows what "art" really is and how to mathematically recreate a representation of any given prompt. I think this was similar to how GitHub Copilot trained their data - instead of copying code from millions of repositories on the stie, they trained the model to know how to handle different situations, and generate its own code instead of pulling it from some data source and giving it to the user. I'm curious to see how this could impact people's trust in things like ChatGPT like you mentioned.
